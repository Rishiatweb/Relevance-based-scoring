{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rishiatweb/Relevance-based-scoring/blob/main/Forest_Fire_detection_experimental(Relevance_scoring).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sGI7G1td1BtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929b97ca-cf44-4a7e-935d-b34d534fe4ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/wildfire-prediction-dataset\n"
          ]
        }
      ],
      "source": [
        "##direct import as similar to kaggle code\n",
        "import kagglehub\n",
        "read_only_path = kagglehub.dataset_download(\"abdelghaniaaba/wildfire-prediction-dataset\")\n",
        "print(\"Path to dataset files:\", read_only_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN1lfkvDHHNt",
        "outputId": "20800096-b075-4d26-8d3f-44e4fe52ae79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Copying dataset from /kaggle/input/wildfire-prediction-dataset to /content/wildfire_dataset_writable...\n",
            "Copying complete.\n",
            "\n",
            "Updated paths to writable directories:\n",
            "Train directory: /content/wildfire_dataset_writable/train (Exists: True)\n",
            "Validation directory: /content/wildfire_dataset_writable/valid (Exists: True)\n",
            "Test directory: /content/wildfire_dataset_writable/test (Exists: True)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "#source and destination paths\n",
        "source_dir = read_only_path\n",
        "writable_dir = \"/content/wildfire_dataset_writable\"\n",
        "\n",
        "#Copying the entire directory tree to play with it on our own merit\n",
        "print(f\"\\nCopying dataset from {source_dir} to {writable_dir}...\")\n",
        "if os.path.exists(writable_dir):\n",
        "    shutil.rmtree(writable_dir) # Remove if it exists to ensure a fresh copy\n",
        "shutil.copytree(source_dir, writable_dir)\n",
        "print(\"Copying complete.\")\n",
        "\n",
        "train_dir = os.path.join(writable_dir, 'train')\n",
        "valid_dir = os.path.join(writable_dir, 'valid')\n",
        "test_dir = os.path.join(writable_dir, 'test')\n",
        "\n",
        "#Verifying new paths to check if previous problems are not bothering me\n",
        "print(\"\\nUpdated paths to writable directories:\")\n",
        "print(f\"Train directory: {train_dir} (Exists: {os.path.exists(train_dir)})\")\n",
        "print(f\"Validation directory: {valid_dir} (Exists: {os.path.exists(valid_dir)})\")\n",
        "print(f\"Test directory: {test_dir} (Exists: {os.path.exists(test_dir)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IEtGno_GE0hF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5d14ffe-0eed-415c-8b2c-b4269cfe482a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Cleaning Writable Train Directory ---\n",
            "Scanning directory: /content/wildfire_dataset_writable/train\n",
            "--> Found problematic file for TensorFlow: /content/wildfire_dataset_writable/train/nowildfire/-114.152378,51.027198.jpg\n",
            "\n",
            "Found 1 problematic files. Removing them...\n",
            "Successfully removed: /content/wildfire_dataset_writable/train/nowildfire/-114.152378,51.027198.jpg\n",
            "Removal complete.\n",
            "\n",
            "Scanned 30250 files in total in /content/wildfire_dataset_writable/train.\n",
            "\n",
            "--- Cleaning Writable Validation Directory ---\n",
            "Scanning directory: /content/wildfire_dataset_writable/valid\n",
            "No problematic files found by TensorFlow decoder.\n",
            "\n",
            "Scanned 6300 files in total in /content/wildfire_dataset_writable/valid.\n",
            "\n",
            "--- Cleaning Writable Test Directory ---\n",
            "Scanning directory: /content/wildfire_dataset_writable/test\n",
            "--> Found problematic file for TensorFlow: /content/wildfire_dataset_writable/test/wildfire/-73.15884,46.38819.jpg\n",
            "\n",
            "Found 1 problematic files. Removing them...\n",
            "Successfully removed: /content/wildfire_dataset_writable/test/wildfire/-73.15884,46.38819.jpg\n",
            "Removal complete.\n",
            "\n",
            "Scanned 6300 files in total in /content/wildfire_dataset_writable/test.\n",
            "\n",
            "\n",
            "Dataset cleaning finished. Proceeding to load data...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def find_and_remove_tf_unreadable_images(base_dir):\n",
        "    corrupt_files = []\n",
        "    total_files = 0\n",
        "    print(f\"Scanning directory: {base_dir}\")\n",
        "    for root, _, files in os.walk(base_dir):\n",
        "        for file in files:\n",
        "            total_files += 1\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                raw_image = tf.io.read_file(file_path)\n",
        "                tf.io.decode_jpeg(raw_image)\n",
        "            except tf.errors.InvalidArgumentError as e:\n",
        "                print(f\"--> Found problematic file for TensorFlow: {file_path}\")\n",
        "                corrupt_files.append(file_path)\n",
        "            except Exception as e:\n",
        "                print(f\"--> Found other problematic file: {file_path} - Error: {e}\")\n",
        "                corrupt_files.append(file_path)\n",
        "\n",
        "    if corrupt_files:\n",
        "        print(f\"\\nFound {len(corrupt_files)} problematic files. Removing them...\")\n",
        "        for file_path in corrupt_files:\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"Successfully removed: {file_path}\")\n",
        "            except OSError as e:\n",
        "                print(f\"Error removing file {file_path}: {e}\")\n",
        "        print(\"Removal complete.\")\n",
        "    else:\n",
        "        print(\"No problematic files found by TensorFlow decoder.\")\n",
        "    print(f\"\\nScanned {total_files} files in total in {base_dir}.\")\n",
        "\n",
        "#cleaning process\n",
        "print(\"\\n--- Cleaning Writable Train Directory ---\")\n",
        "find_and_remove_tf_unreadable_images(train_dir)\n",
        "print(\"\\n--- Cleaning Writable Validation Directory ---\")\n",
        "find_and_remove_tf_unreadable_images(valid_dir)\n",
        "print(\"\\n--- Cleaning Writable Test Directory ---\")\n",
        "find_and_remove_tf_unreadable_images(test_dir)\n",
        "print(\"\\n\\nDataset cleaning finished. Proceeding to load data...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j8-AIHEC69iQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yrq15CKKD-J-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13db15d9-a99c-4450-a4aa-2e56bf5ce5ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 30249 files belonging to 2 classes.\n",
            "Found 6300 files belonging to 2 classes.\n",
            "Found 6299 files belonging to 2 classes.\n",
            "Class Names: ['nowildfire', 'wildfire']\n"
          ]
        }
      ],
      "source": [
        "#Constants to play around with\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir, labels='inferred', label_mode='binary', image_size=IMG_SIZE,\n",
        "    interpolation='nearest', batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    valid_dir, labels='inferred', label_mode='binary', image_size=IMG_SIZE,\n",
        "    interpolation='nearest', batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir, labels='inferred', label_mode='binary', image_size=IMG_SIZE,\n",
        "    interpolation='nearest', batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "class_names = train_dataset.class_names\n",
        "print(\"Class Names:\", class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d_OBLk0lER6l"
      },
      "outputs": [],
      "source": [
        "data_augmentation = Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "], name=\"data_augmentation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sdYFtk_NEW0X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aefd0215-7a14-49cb-cece-2b25db46dbb2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"custom_cnn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"custom_cnn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (\u001b[38;5;33mSequential\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ data_augmentation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Custom CNN ---\n",
            "Epoch 1/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 70ms/step - accuracy: 0.8872 - loss: 0.2797 - val_accuracy: 0.9032 - val_loss: 0.2649\n",
            "Epoch 2/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 68ms/step - accuracy: 0.9241 - loss: 0.1928 - val_accuracy: 0.9240 - val_loss: 0.1998\n",
            "Epoch 3/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.9377 - loss: 0.1688 - val_accuracy: 0.9508 - val_loss: 0.1399\n",
            "Epoch 4/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 69ms/step - accuracy: 0.9456 - loss: 0.1496 - val_accuracy: 0.9494 - val_loss: 0.1452\n",
            "Epoch 5/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.9469 - loss: 0.1445 - val_accuracy: 0.9444 - val_loss: 0.1852\n",
            "Epoch 6/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 84ms/step - accuracy: 0.9488 - loss: 0.1446 - val_accuracy: 0.9254 - val_loss: 0.2402\n",
            "Epoch 7/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 75ms/step - accuracy: 0.9513 - loss: 0.1340 - val_accuracy: 0.9587 - val_loss: 0.1212\n",
            "Epoch 8/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 93ms/step - accuracy: 0.9543 - loss: 0.1279 - val_accuracy: 0.9421 - val_loss: 0.1625\n",
            "Epoch 9/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 96ms/step - accuracy: 0.9554 - loss: 0.1213 - val_accuracy: 0.9510 - val_loss: 0.1647\n",
            "Epoch 10/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 69ms/step - accuracy: 0.9548 - loss: 0.1242 - val_accuracy: 0.9541 - val_loss: 0.1364\n",
            "Epoch 11/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.9586 - loss: 0.1152 - val_accuracy: 0.9573 - val_loss: 0.1436\n",
            "Epoch 12/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 81ms/step - accuracy: 0.9602 - loss: 0.1115 - val_accuracy: 0.9402 - val_loss: 0.2292\n",
            "Epoch 13/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 92ms/step - accuracy: 0.9582 - loss: 0.1145 - val_accuracy: 0.9632 - val_loss: 0.1198\n",
            "Epoch 14/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 93ms/step - accuracy: 0.9618 - loss: 0.1077 - val_accuracy: 0.9614 - val_loss: 0.1147\n",
            "Epoch 15/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 73ms/step - accuracy: 0.9617 - loss: 0.1056 - val_accuracy: 0.9287 - val_loss: 0.2950\n",
            "Epoch 16/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 67ms/step - accuracy: 0.9621 - loss: 0.1091 - val_accuracy: 0.9427 - val_loss: 0.2804\n",
            "Epoch 17/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 69ms/step - accuracy: 0.9629 - loss: 0.1035 - val_accuracy: 0.9584 - val_loss: 0.1435\n",
            "Epoch 18/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 68ms/step - accuracy: 0.9656 - loss: 0.0989 - val_accuracy: 0.9611 - val_loss: 0.1263\n",
            "Epoch 19/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 67ms/step - accuracy: 0.9648 - loss: 0.0970 - val_accuracy: 0.9654 - val_loss: 0.1035\n",
            "Epoch 20/20\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 68ms/step - accuracy: 0.9647 - loss: 0.0973 - val_accuracy: 0.9611 - val_loss: 0.1479\n"
          ]
        }
      ],
      "source": [
        "custom_cnn = Sequential([\n",
        "    Input(shape=IMG_SIZE + (3,)),\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    data_augmentation,\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "], name=\"custom_cnn\")\n",
        "\n",
        "custom_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "custom_cnn.summary()\n",
        "\n",
        "print(\"\\n--- Training Custom CNN ---\")\n",
        "history_cnn = custom_cnn.fit(\n",
        "    train_dataset,\n",
        "    epochs=20,\n",
        "    validation_data=validation_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go-W6Lo_HqBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c30bf1-1de6-4c29-ddc0-d9f8dbc3073f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "\n",
            "--- Training Transfer Learning Model (Feature Extraction) ---\n",
            "Epoch 1/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 82ms/step - accuracy: 0.9049 - loss: 0.2449 - val_accuracy: 0.9475 - val_loss: 0.1370\n",
            "Epoch 2/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 70ms/step - accuracy: 0.9371 - loss: 0.1745 - val_accuracy: 0.9500 - val_loss: 0.1366\n",
            "Epoch 3/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 80ms/step - accuracy: 0.9390 - loss: 0.1624 - val_accuracy: 0.9522 - val_loss: 0.1242\n",
            "Epoch 4/10\n",
            "\u001b[1m946/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 70ms/step - accuracy: 0.9406 - loss: 0.1616 - val_accuracy: 0.9527 - val_loss: 0.1257\n",
            "Epoch 5/10\n",
            "\u001b[1m752/946\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.9397 - loss: 0.1574"
          ]
        }
      ],
      "source": [
        "#Feature Extraction\n",
        "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = Input(shape=IMG_SIZE + (3,))\n",
        "x = tf.keras.layers.Rescaling(1./255)(inputs)\n",
        "x = data_augmentation(x)\n",
        "x = base_model(x, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "transfer_model = Model(inputs, outputs)\n",
        "\n",
        "transfer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                       loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Transfer Learning Model (Feature Extraction) ---\")\n",
        "history_transfer = transfer_model.fit(train_dataset, epochs=10, validation_data=validation_dataset)\n",
        "\n",
        "#Part B: Fine-Tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "transfer_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                       loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training Transfer Learning Model (Fine-Tuning) ---\")\n",
        "history_fine_tune = transfer_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=history_transfer.epoch[-1] + 10,\n",
        "    initial_epoch=history_transfer.epoch[-1],\n",
        "    validation_data=validation_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ej_VPICkW9dP"
      },
      "outputs": [],
      "source": [
        "#this was just done because i am doing a research project regarding scoring methods and their fallacies,\n",
        "#and Resnet's scores would be used to compare with other models, as part of one of the experiments including these\n",
        "#Model 3: Transfer Learning with ResNet50\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "print(\"\\n\\n--- Setting up ResNet50 Model ---\")\n",
        "\n",
        "#Feature Extraction\n",
        "base_model_resnet = ResNet50(\n",
        "    input_shape=IMG_SIZE + (3,),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model_resnet.trainable = False\n",
        "inputs_resnet = Input(shape=IMG_SIZE + (3,))\n",
        "x_resnet = data_augmentation(inputs_resnet)\n",
        "x_resnet = tf.keras.applications.resnet.preprocess_input(x_resnet)\n",
        "x_resnet = base_model_resnet(x_resnet, training=False)\n",
        "x_resnet = GlobalAveragePooling2D()(x_resnet)\n",
        "x_resnet = Dropout(0.2)(x_resnet)\n",
        "outputs_resnet = Dense(1, activation='sigmoid')(x_resnet)\n",
        "\n",
        "resnet_model = Model(inputs_resnet, outputs_resnet, name=\"resnet50_transfer_model\")\n",
        "\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "resnet_model.summary()\n",
        "print(\"\\n--- Training ResNet50 Model (Feature Extraction) ---\")\n",
        "history_resnet = resnet_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10, # Keeping epochs consistent for comparison\n",
        "    validation_data=validation_dataset,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Fine-Tuning\n",
        "base_model_resnet.trainable = True\n",
        "#fine-tuning a smaller portion of ResNet as it's a larger model, and i had some problems(blackout)\n",
        "#unfreezing from the last convolutional block (e.g., from layer ~143 onwards).\n",
        "for layer in base_model_resnet.layers[:143]:\n",
        "    layer.trainable = False\n",
        "resnet_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "print(\"\\n--- Training ResNet50 Model (Fine-Tuning) ---\")\n",
        "history_fine_tune_resnet = resnet_model.fit(\n",
        "    train_dataset,\n",
        "    epochs=history_resnet.epoch[-1] + 10,\n",
        "    initial_epoch=history_resnet.epoch[-1],\n",
        "    validation_data=validation_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne7D6Yc5Gof0"
      },
      "outputs": [],
      "source": [
        "#Getting true labels and predictions for alll three models\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0).flatten()\n",
        "y_pred_cnn_prob = custom_cnn.predict(test_dataset).flatten()\n",
        "y_pred_cnn = (y_pred_cnn_prob > 0.5).astype(int)\n",
        "y_pred_transfer_prob = transfer_model.predict(test_dataset).flatten()\n",
        "y_pred_transfer = (y_pred_transfer_prob > 0.5).astype(int)\n",
        "y_pred_resnet_prob = resnet_model.predict(test_dataset).flatten()\n",
        "y_pred_resnet = (y_pred_resnet_prob > 0.5).astype(int)\n",
        "\n",
        "print(\"\\n--- Custom CNN Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred_cnn, target_names=class_names))\n",
        "\n",
        "print(\"\\n--- Transfer Learning Model Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred_transfer, target_names=class_names))\n",
        "\n",
        "print(\"\\n--- ResNet50 Model Classification Report ---\")\n",
        "print(classification_report(y_true, y_pred_resnet, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnAW5fbjHz2Q"
      },
      "outputs": [],
      "source": [
        "#Plots of Confusion Matrices(for each)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(21, 6))\n",
        "#Custom CNN's plot\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_cnn, display_labels=class_names, ax=axes[0], cmap=plt.cm.Blues)\n",
        "axes[0].set_title('Custom CNN Confusion Matrix')\n",
        "#MobileNetV2's plot\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_transfer, display_labels=class_names, ax=axes[1], cmap=plt.cm.Blues)\n",
        "axes[1].set_title('MobileNetV2 Model Confusion Matrix')\n",
        "#ResNet50's plot\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred_resnet, display_labels=class_names, ax=axes[2], cmap=plt.cm.Blues)\n",
        "axes[2].set_title('ResNet50 Model Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#ROC Curves\n",
        "fpr_cnn, tpr_cnn, _ = roc_curve(y_true, y_pred_cnn_prob)\n",
        "roc_auc_cnn = auc(fpr_cnn, tpr_cnn)\n",
        "fpr_transfer, tpr_transfer, _ = roc_curve(y_true, y_pred_transfer_prob)\n",
        "roc_auc_transfer = auc(fpr_transfer, tpr_transfer)\n",
        "fpr_resnet, tpr_resnet, _ = roc_curve(y_true, y_pred_resnet_prob)\n",
        "roc_auc_resnet = auc(fpr_resnet, tpr_resnet)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr_cnn, tpr_cnn, color='blue', lw=2, label=f'Custom CNN (AUC = {roc_auc_cnn:.4f})')\n",
        "plt.plot(fpr_transfer, tpr_transfer, color='yellow', lw=2, label=f'MobileNet (AUC = {roc_auc_transfer:.4f})')\n",
        "plt.plot(fpr_resnet, tpr_resnet, color='red', lw=2, label=f'ResNet50 (AUC = {roc_auc_resnet:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve Comparison', fontsize=14)\n",
        "plt.legend(loc=\"lower right\", fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "import pandas as pd\n",
        "print(\"Generating Final Performance Metrics Table\")\n",
        "model_predictions = {\n",
        "    'Custom CNN': {\n",
        "        'predictions': y_pred_cnn,\n",
        "        'probabilities': y_pred_cnn_prob\n",
        "    },\n",
        "    'MobileNetV2': {\n",
        "        'predictions': y_pred_transfer,\n",
        "        'probabilities': y_pred_transfer_prob\n",
        "    },\n",
        "    'ResNet50':{\n",
        "        'predictions': y_pred_resnet,\n",
        "        'probabilities': y_pred_resnet_prob\n",
        "    }\n",
        "}\n",
        "evaluation_results = []\n",
        "for model_name, data in model_predictions.items():\n",
        "  y_pred = data['predictions']\n",
        "  y_prob = data['probabilities']\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  auc_score = roc_auc_score(y_true, y_prob)\n",
        "  f1 = f1_score(y_true, y_pred, pos_label=1)\n",
        "  evaluation_results.append({\n",
        "      'Model': model_name,\n",
        "      'Accuracy': accuracy,\n",
        "      'Precision': precision,\n",
        "      'Recall': recall,\n",
        "      'AUC': auc_score,\n",
        "      'F1 Score': f1\n",
        "  })\n",
        "  results_df = pd.DataFrame(evaluation_results)\n",
        "  results_df.set_index('Model', inplace=True)\n",
        "print(results_df.round(4))\n",
        "print(\"Evaluation is complete\")"
      ],
      "metadata": {
        "id": "F53TGHHfBBMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}